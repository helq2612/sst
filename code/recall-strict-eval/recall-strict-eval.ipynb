{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "import urllib2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import matlab\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def segment_tiou(target_segments, test_segments):\n",
    "    \"\"\"Compute intersection over union btw segments\n",
    "    Parameters\n",
    "    ----------\n",
    "    target_segments : ndarray\n",
    "        2-dim array in format [m x 2:=[init, end]]\n",
    "    test_segments : ndarray\n",
    "        2-dim array in format [n x 2:=[init, end]]\n",
    "    Outputs\n",
    "    -------\n",
    "    tiou : ndarray\n",
    "        2-dim array [m x n] with IOU ratio.\n",
    "    Note: It assumes that target-segments are more scarce that test-segments\n",
    "    \"\"\"\n",
    "    if target_segments.ndim != 2 or test_segments.ndim != 2:\n",
    "        raise ValueError('Dimension of arguments is incorrect')\n",
    "\n",
    "    m, n = target_segments.shape[0], test_segments.shape[0]\n",
    "    tiou = np.empty((m, n))\n",
    "    for i in xrange(m):\n",
    "        tt1 = np.maximum(target_segments[i, 0], test_segments[:, 0])\n",
    "        tt2 = np.minimum(target_segments[i, 1], test_segments[:, 1])\n",
    "\n",
    "        # Non-negative overlap score\n",
    "        intersection = (tt2 - tt1 + 1.0).clip(0)\n",
    "        union = ((test_segments[:, 1] - test_segments[:, 0] + 1) +\n",
    "                 (target_segments[i, 1] - target_segments[i, 0] + 1) -\n",
    "                 intersection)\n",
    "        # Compute overlap as the ratio of the intersection\n",
    "        # over union of two segments at the frame level.\n",
    "        tiou[i, :] = intersection / union\n",
    "    return tiou\n",
    "\n",
    "\n",
    "def average_recall_vs_nr_proposals(proposals, ground_truth,\n",
    "                                   tiou_thresholds=np.linspace(0.5, 1.0, 11)):\n",
    "    \"\"\" Computes the average recall given an average number \n",
    "        of proposals per video.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    proposals : DataFrame\n",
    "        pandas table with the resulting proposals. It must include \n",
    "        the following columns: {'video-name': (str) Video identifier,\n",
    "                                'f-init': (int) Starting index Frame,\n",
    "                                'f-end': (int) Ending index Frame,\n",
    "                                'score': (float) Proposal confidence}\n",
    "    ground_truth : DataFrame\n",
    "        pandas table with annotations of the dataset. It must include \n",
    "        the following columns: {'video-name': (str) Video identifier,\n",
    "                                'f-init': (int) Starting index Frame,\n",
    "                                'f-end': (int) Ending index Frame}\n",
    "    tiou_thresholds : 1darray, optional\n",
    "        array with tiou threholds.\n",
    "        \n",
    "    Outputs\n",
    "    -------\n",
    "    average_recall : 1darray\n",
    "        recall averaged over a list of tiou threshold.\n",
    "    proposals_per_video : 1darray\n",
    "        average number of proposals per video.\n",
    "    \"\"\"\n",
    "    # Get list of videos.\n",
    "    video_lst = proposals['video-name'].unique()\n",
    "    \n",
    "    # For each video, computes tiou scores among the retrieved proposals.\n",
    "    score_lst = []\n",
    "    for videoid in video_lst:\n",
    "        \n",
    "        # Get proposals for this video.\n",
    "        prop_idx = proposals['video-name'] == videoid\n",
    "        this_video_proposals = proposals[prop_idx][['f-init', \n",
    "                                                    'f-end']].values\n",
    "        # Sort proposals by score.\n",
    "        sort_idx = proposals[prop_idx]['score'].argsort()[::-1]\n",
    "        this_video_proposals = this_video_proposals[sort_idx, :]\n",
    "        \n",
    "        # Get ground-truth instances associated to this video.\n",
    "        gt_idx = ground_truth['video-name'] == videoid\n",
    "        this_video_ground_truth = ground_truth[gt_idx][['f-init', \n",
    "                                                        'f-end']].values\n",
    "        \n",
    "        # Compute tiou scores.\n",
    "        tiou = segment_tiou(this_video_ground_truth, this_video_proposals)\n",
    "        score_lst.append(tiou)\n",
    "    \n",
    "    # Given that the length of the videos is really varied, we \n",
    "    # compute the number of proposals in terms of a ratio of the total \n",
    "    # proposals retrieved, i.e. average recall at a percentage of proposals \n",
    "    # retrieved per video.\n",
    "    \n",
    "    # Computes average recall.\n",
    "    pcn_lst = np.arange(1, 101) / 100.0\n",
    "    matches = np.empty((video_lst.shape[0], pcn_lst.shape[0]))\n",
    "    positives = np.empty(video_lst.shape[0])\n",
    "    recall = np.empty((tiou_thresholds.shape[0], pcn_lst.shape[0]))\n",
    "    # Iterates over each tiou threshold.\n",
    "    for ridx, tiou in enumerate(tiou_thresholds):\n",
    "        \n",
    "        # Inspect positives retrieved per video at different \n",
    "        # number of proposals (percentage of the total retrieved).\n",
    "        for i, score in enumerate(score_lst):\n",
    "            # Total positives per video.\n",
    "            positives[i] = score.shape[0]\n",
    "            \n",
    "            for j, pcn in enumerate(pcn_lst):\n",
    "                # Get number of proposals as a percentage of total retrieved.\n",
    "                nr_proposals = int(score.shape[1] * pcn)\n",
    "                # Find proposals that satisfies minimum tiou threhold.\n",
    "                matches[i, j] = ((score[:, :nr_proposals] >= tiou).sum(axis=1) > 0).sum()\n",
    "        \n",
    "        # Computes recall given the set of matches per video.\n",
    "        recall[ridx, :] = matches.sum(axis=0) / positives.sum()\n",
    "    \n",
    "    # Recall is averaged.\n",
    "    recall = recall.mean(axis=0)\n",
    "        \n",
    "    # Get the average number of proposals per video.\n",
    "    proposals_per_video = pcn_lst * (float(proposals.shape[0]) / video_lst.shape[0])\n",
    "    \n",
    "    return recall, proposals_per_video\n",
    "\n",
    "\n",
    "def recall_vs_tiou_thresholds(proposals, ground_truth, nr_proposals=1000,\n",
    "                              tiou_thresholds=np.arange(0.05, 1.05, 0.05)):\n",
    "    \"\"\" Computes recall at different tiou thresholds given a fixed \n",
    "        average number of proposals per video.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    proposals : DataFrame\n",
    "        pandas table with the resulting proposals. It must include \n",
    "        the following columns: {'video-name': (str) Video identifier,\n",
    "                                'f-init': (int) Starting index Frame,\n",
    "                                'f-end': (int) Ending index Frame,\n",
    "                                'score': (float) Proposal confidence}\n",
    "    ground_truth : DataFrame\n",
    "        pandas table with annotations of the dataset. It must include \n",
    "        the following columns: {'video-name': (str) Video identifier,\n",
    "                                'f-init': (int) Starting index Frame,\n",
    "                                'f-end': (int) Ending index Frame}\n",
    "    nr_proposals : int\n",
    "        average number of proposals per video.\n",
    "    tiou_thresholds : 1darray, optional\n",
    "        array with tiou threholds.\n",
    "        \n",
    "    Outputs\n",
    "    -------\n",
    "    average_recall : 1darray\n",
    "        recall averaged over a list of tiou threshold.\n",
    "    proposals_per_video : 1darray\n",
    "        average number of proposals per video.\n",
    "    \"\"\"\n",
    "    # Get list of videos.\n",
    "    video_lst = proposals['video-name'].unique()\n",
    "    \n",
    "    # For each video, computes tiou scores among the retrieved proposals.\n",
    "    score_lst = []\n",
    "    for videoid in video_lst:\n",
    "        \n",
    "        # Get proposals for this video.\n",
    "        prop_idx = proposals['video-name'] == videoid\n",
    "        this_video_proposals = proposals[prop_idx][['f-init', \n",
    "                                                    'f-end']].values\n",
    "        # Sort proposals by score.\n",
    "        sort_idx = proposals[prop_idx]['score'].argsort()[::-1]\n",
    "        this_video_proposals = this_video_proposals[sort_idx, :]\n",
    "        \n",
    "        # Get ground-truth instances associated to this video.\n",
    "        gt_idx = ground_truth['video-name'] == videoid\n",
    "        this_video_ground_truth = ground_truth[gt_idx][['f-init', \n",
    "                                                        'f-end']].values\n",
    "        \n",
    "        # Compute tiou scores.\n",
    "        tiou = segment_tiou(this_video_ground_truth, this_video_proposals)\n",
    "        score_lst.append(tiou)\n",
    "    \n",
    "    # To obtain the average number of proposals, we need to define a \n",
    "    # percentage of proposals to get per video.\n",
    "    pcn = (video_lst.shape[0] * float(nr_proposals)) / proposals.shape[0]\n",
    "    \n",
    "    # Computes recall at different tiou thresholds.\n",
    "    matches = np.empty((video_lst.shape[0], tiou_thresholds.shape[0]))\n",
    "    positives = np.empty(video_lst.shape[0])\n",
    "    recall = np.empty(tiou_thresholds.shape[0])\n",
    "    # Iterates over each tiou threshold.\n",
    "    for ridx, tiou in enumerate(tiou_thresholds):\n",
    "        \n",
    "        for i, score in enumerate(score_lst):\n",
    "            # Total positives per video.\n",
    "            positives[i] = score.shape[0]\n",
    "            \n",
    "            # Get number of proposals at the fixed percentage of total retrieved.\n",
    "            nr_proposals = int(score.shape[1] * pcn)\n",
    "            # Find proposals that satisfies minimum tiou threhold.\n",
    "            matches[i, ridx] = ((score[:, :nr_proposals] >= tiou).sum(axis=1) > 0).sum()\n",
    "        \n",
    "        # Computes recall given the set of matches per video.\n",
    "        recall[ridx] = matches[:, ridx].sum(axis=0) / positives.sum()\n",
    "    \n",
    "    return recall, tiou_thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze the results in the THUMOS'14 test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Retrieves and loads Thumos14 test set ground-truth.\n",
    "ground_truth_url = ('https://gist.githubusercontent.com/cabaf/'\n",
    "                    'ed34a35ee4443b435c36de42c4547bd7/raw/'\n",
    "                    '4baab2f4b47e1d91006f420d9f8d527037f7b95d/'\n",
    "                    'thumos14_test_groundtruth.csv')\n",
    "s = requests.get(ground_truth_url).content\n",
    "ground_truth = pd.read_csv(io.StringIO(s.decode('utf-8')), sep=' ')\n",
    "video_list = ground_truth['video-name'].unique()\n",
    "\n",
    "# Retrieves and loads proposal results.\n",
    "# Update here for your method if needed!\n",
    "proposals_dirname = '../../data/proposals/'\n",
    "methodname = 'sst'\n",
    "prop_filename = proposals_dirname + 'sst_k32_th14_prop.csv'\n",
    "\n",
    "avg_recall_file = 'average_recall.json'\n",
    "recall_file = 'recall_vs_tiou.json'\n",
    "\n",
    "prop_results_all = pd.read_csv(prop_filename, sep=' ')\n",
    "idx = prop_results_all['video-name'].isin(video_list)\n",
    "prop_results = prop_results_all[idx].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recall analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Computes average recall vs average number of proposals.\n",
    "average_recall, average_nr_proposals = average_recall_vs_nr_proposals(\n",
    "    prop_results, ground_truth, tiou_thresholds=np.arange(0.7, 0.96, 0.05))\n",
    "\n",
    "# Computes recall for different tiou thresholds at a fixed number of proposals.\n",
    "recall, tiou_thresholds = recall_vs_tiou_thresholds(\n",
    "    prop_results, ground_truth, nr_proposals=1000)\n",
    "\n",
    "average_recall = average_recall.tolist()\n",
    "average_nr_proposals = average_nr_proposals.tolist()\n",
    "\n",
    "# retrieve strict-average-recall\n",
    "strict_average_recall_url = (\"https://gist.githubusercontent.com/shyamal-b/\"\n",
    "                             \"9c3edd45bc024606d7d076d749850559/raw/\"\n",
    "                             \"ef37591a340fb3fdb145ee77ee87990932cae015/\"\n",
    "                             \"average_recall_strict.json\")\n",
    "r = urllib2.urlopen(strict_average_recall_url)\n",
    "strict_average_recall_data = json.load(r)\n",
    "\n",
    "\n",
    "with open(avg_recall_file, 'w') as f:\n",
    "    strict_average_recall_data = {methodname: {'nr_proposals': average_nr_proposals,\n",
    "                          'average_recall': average_recall},}\n",
    "    json.dump(strict_average_recall_data, f, indent=4, sort_keys=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# below code is entirely optional\n",
    "recall = recall.tolist()\n",
    "tiou_thresholds = tiou_thresholds.tolist()\n",
    "\n",
    "with open(recall_file, 'w') as f:\n",
    "    dummy = {methodname: {'recall': recall,\n",
    "                          'tiou': tiou_thresholds},}\n",
    "    json.dump(dummy, f, indent=4, sort_keys=True)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
